{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Explaining MAB"
      ],
      "metadata": {
        "id": "rhFJ4c3HkBcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The MAB agent problem formulation involves finding the ad that maximizes the overall click-through rate (CTR) while balancing the trade-off between exploiting the ad that seems to be the most effective so far and exploring other ads to potentially find a better one. The agent must decide which ad to show at each time step, based on the observed data and the strategy used. The goal is to maximize the expected total reward over a fixed time horizon, taking into account the uncertainty of the rewards and the limited budget for testing each ad.\n",
        "- The MAB agent must balance the exploration of less-known ads to learn their CTRs with the exploitation of the ads that are known to have higher CTRs to maximize the total number of clicks."
      ],
      "metadata": {
        "id": "a87snbEYQ9pV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjOFE6EngghZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ads_clicks = pd.read_csv(\"/content/Ads_Optimisation.csv\")"
      ],
      "metadata": {
        "id": "xYWT0VjpG76e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ads_clicks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E1IkaOY2HdSZ",
        "outputId": "679664fc-46fb-4fd8-9a4d-4fd348b66809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
              "0        1     0     0     0     1     0     0     0     1      0\n",
              "1        0     0     0     0     0     0     0     0     1      0\n",
              "2        0     0     0     0     0     0     0     0     0      0\n",
              "3        0     1     0     0     0     0     0     1     0      0\n",
              "4        0     0     0     0     0     0     0     0     0      0\n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...\n",
              "9995     0     0     1     0     0     0     0     1     0      0\n",
              "9996     0     0     0     0     0     0     0     0     0      0\n",
              "9997     0     0     0     0     0     0     0     0     0      0\n",
              "9998     1     0     0     0     0     0     0     1     0      0\n",
              "9999     0     1     0     0     0     0     0     0     0      0\n",
              "\n",
              "[10000 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-906b6fed-936c-4408-8492-21d69005e49c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ad 1</th>\n",
              "      <th>Ad 2</th>\n",
              "      <th>Ad 3</th>\n",
              "      <th>Ad 4</th>\n",
              "      <th>Ad 5</th>\n",
              "      <th>Ad 6</th>\n",
              "      <th>Ad 7</th>\n",
              "      <th>Ad 8</th>\n",
              "      <th>Ad 9</th>\n",
              "      <th>Ad 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-906b6fed-936c-4408-8492-21d69005e49c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-906b6fed-936c-4408-8492-21d69005e49c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-906b6fed-936c-4408-8492-21d69005e49c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ads_clicks.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chg6n-nrHpp5",
        "outputId": "b659410a-97c4-487a-cb7a-957468f1f160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of       Ad 1  Ad 2  Ad 3  Ad 4  Ad 5  Ad 6  Ad 7  Ad 8  Ad 9  Ad 10\n",
              "0        1     0     0     0     1     0     0     0     1      0\n",
              "1        0     0     0     0     0     0     0     0     1      0\n",
              "2        0     0     0     0     0     0     0     0     0      0\n",
              "3        0     1     0     0     0     0     0     1     0      0\n",
              "4        0     0     0     0     0     0     0     0     0      0\n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...\n",
              "9995     0     0     1     0     0     0     0     1     0      0\n",
              "9996     0     0     0     0     0     0     0     0     0      0\n",
              "9997     0     0     0     0     0     0     0     0     0      0\n",
              "9998     1     0     0     0     0     0     0     1     0      0\n",
              "9999     0     1     0     0     0     0     0     0     0      0\n",
              "\n",
              "[10000 rows x 10 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_ads = len(ads_clicks.columns)\n",
        "num_steps = len(ads_clicks)"
      ],
      "metadata": {
        "id": "1ltDsaPcJV4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize action-value estimates for each ad to 0\n",
        "estimates = np.zeros(num_ads)"
      ],
      "metadata": {
        "id": "_4DJs5vDLDL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Defining the epsilon-greedy method"
      ],
      "metadata": {
        "id": "IBaWQhidi3mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ε-greedy action method\n",
        "def epsilon_greedy(epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, num_ads-1)\n",
        "    else:\n",
        "        return np.argmax(estimates)"
      ],
      "metadata": {
        "id": "w69u_oqbLIUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Defining the ucb method"
      ],
      "metadata": {
        "id": "LI3k8dzDi9-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the UCB action method \n",
        "def ucb(c):\n",
        "    # Compute the UCB value for each ad\n",
        "    n = np.sum(action_counts)\n",
        "    ucb_values = estimates + c * np.sqrt(np.log(n) / (action_counts + 1e-5))\n",
        "    # Choose the ad with the highest UCB value\n",
        "    return np.argmax(ucb_values)"
      ],
      "metadata": {
        "id": "HORrYIoBLTeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's use these functions to compute the total rewards after 2000 time steps for both the ε-greedy and UCB action methods:"
      ],
      "metadata": {
        "id": "xaExCLlRLc8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize counts for each ad to 0\n",
        "action_counts = np.zeros(num_ads)"
      ],
      "metadata": {
        "id": "DJ18D6IlLW5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ε-greedy action with ε=0.01 "
      ],
      "metadata": {
        "id": "UP3LmMD0jD9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the ε-greedy action with ε=0.01 for 2000 time steps\n",
        "epsilon = 0.01\n",
        "total_reward_eps01 = 0\n",
        "for t in range(num_steps):\n",
        "    action = epsilon_greedy(epsilon)\n",
        "    action_counts[action] += 1\n",
        "    reward = ads_clicks.iloc[t, action]\n",
        "    try:\n",
        "      total_reward_eps01 += reward\n",
        "      estimates[action] += (reward - estimates[action]) / action_counts[action]\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "Q8UJzeIXLfcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ε = 0.01, the ε-greedy action will mostly exploit the ad that has the highest estimated value, and only occasionally explore other ads. This can lead to a slow convergence to the optimal ad, but once the agent has a good estimate of the best ad, it will consistently choose it and achieve high rewards. "
      ],
      "metadata": {
        "id": "l2KpDxN-R7Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ε-greedy action with ε=0.3 "
      ],
      "metadata": {
        "id": "eJoycBPljL7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import execlp\n",
        "# Run the ε-greedy action with ε=0.3 for 2000 time steps\n",
        "epsilon = 0.3\n",
        "total_reward_eps03 = 0\n",
        "for t in range(num_steps):\n",
        "    action = epsilon_greedy(epsilon)\n",
        "    action_counts[action] += 1\n",
        "    reward = ads_clicks.iloc[t, action]\n",
        "    #print(reward)\n",
        "    #print(\"\\n\")\n",
        "    try:\n",
        "      total_reward_eps03 += reward\n",
        "      estimates[action] += (reward - estimates[action]) / action_counts[action]\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "_L09weMpLqTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ε = 0.3, the agent will explore more frequently, which can lead to a faster convergence to the optimal ad but can also result in lower rewards if the exploration is too random."
      ],
      "metadata": {
        "id": "aVEskB6oSZE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the UCB action with c=1.5 for 2000 time steps\n",
        "c = 1.5\n",
        "total_reward_ucb = 0\n",
        "for t in range(num_steps):\n",
        "    # Choose an ad using the UCB action\n",
        "    action = ucb(c)\n",
        "    # Update the count and estimated value for the chosen ad\n",
        "    action_counts[action] += 1\n",
        "    reward = ads_clicks.iloc[t, action]\n",
        "    total_reward_ucb += reward\n",
        "    estimates[action] += (reward - estimates[action]) / action_counts[action]"
      ],
      "metadata": {
        "id": "pghET9RgL1Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total reward for ε-greedy with ε=0.01:\", total_reward_eps01)\n",
        "print(\"Total reward for ε-greedy with ε=0.3:\", total_reward_eps03)\n",
        "print(\"Total reward for UCB with c=1.5:\", total_reward_ucb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55QDODiYL74n",
        "outputId": "15fa12b8-3eda-4299-93e0-93b144f3f593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reward for ε-greedy with ε=0.01: 2171\n",
            "Total reward for ε-greedy with ε=0.3: 2274\n",
            "Total reward for UCB with c=1.5: 2315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Explaining how the action value estimate compares to optimal action "
      ],
      "metadata": {
        "id": "qddUKtR0jWbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For all approaches, the action value estimated will initially be uncertain, but as more data is collected, the estimate will become more accurate. \n",
        "- The ε-greedy action with ε = 0.01 will eventually converge to the optimal ad and achieve high rewards, but this can take longer than the more exploratory ε-greedy action with ε = 0.3 or the UCB action method. \n",
        "- The UCB action method will explore more systematically and converge faster to the optimal ad, but its performance can be sensitive to the choice of the parameter c. \n",
        "- Overall, the success of each approach will depend on the specific characteristics of the data and the environment."
      ],
      "metadata": {
        "id": "u1Dchca1Swv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the MAB problem, the goal is to maximize the total reward obtained over a sequence of actions. The optimal action at any time step is the one that would result in the highest expected reward, given the current state of the system.\n",
        "\n",
        "- For the ε-greedy action method, the estimated action values are updated based on the rewards obtained for each action over time. The estimated value for each action is calculated as the average reward obtained when that action is taken. As the number of times each action is taken increases, the estimates become more accurate. However, the estimates may be biased if certain actions are not taken often enough, which can lead to suboptimal performance.\n",
        "\n",
        "- The UCB action method addresses the bias problem by taking into account not only the average reward obtained for each action, but also the variance in the rewards and the number of times each action has been taken. The UCB action method chooses actions that have a high estimated value as well as high uncertainty, which can lead to more exploration of the action space and better overall performance.\n",
        "\n",
        "- In general, both the ε-greedy and UCB action methods will converge to the optimal action over time as more data is collected and the estimates become more accurate. \n",
        "- However, the UCB action method may converge faster since it takes into account uncertainty and encourages exploration of less certain actions. \n",
        "- In some cases, the ε-greedy action method may get stuck in a suboptimal action for longer if it is not able to explore other options effectively."
      ],
      "metadata": {
        "id": "79ECefZ7TZwR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ledPvi_PL9pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}